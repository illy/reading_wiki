Some of the discrepancies are positive, the remainder negative. But it is the magnitude of the discrepancy rather than its direction which is of interest to us; the sign has no importance.

It will be helpful to square the discrepancies here.

It should be clear that it is not the absolute discrepancy between observed and expected frequencies which is important.

__Relative discrepancy__: dividing the square of each absolute discrepancy by the expected frequency.

__Chi-square test__:

1. The measure of __deviance__ from the model for each class which will be zero when the observed frequency of scores in the class is exactly what would be predicted by H0 and which will be large and positive when the discrepancy is large compared to the expected value.

2. Using the total deviance as a test statistics, we are now in a position to decide whether or not the sample scores are consistent with their being drawn from a population provided that all the expected frequencies within classes are large enough, the distribution of the total deviance is known when H0 is true.

3. The degrees of freedom depend on the number of classes which have contributed to the total deviance.

4. Given the largish sample size and the fact that the value of the test statistic is well below the critical value, it is highly unlikely that any serious error will be committed by accepting that H0 is true.

The degrees of freedom can be considered in a sense as the number of independent pieces of information we have on which to base the test of a hypothesis.

In estimating the population mean and standard deviation for the sample, we have, if yo like, extracted two piece of information from the data (one to estimate the mean and another to estimate the standard deviation), reducing by two the number of pieces of information available for checking the fit of the model to the data.

However, we must not forget there is a probability of 5% that the result of the test is misleading and that the test scores really are normally distributed, or at least have a distribution sufficiently close to normal to meet the requirements of test.

If the data do not meet the assumption of normality, the results of factor analysis or regression analysis (if carried out) should be treated with extra caution.

What we must ask ourselves now is whether the differences observed could be due simply to sampling variation, that is, we have two samples drawn from the same population; or whether they indicate a real difference, that is, the two samples are actually from different populations.

The __expected frequencies__ of different numbers of errors in each group can be obtained by multiplying the total frequency of a given number of errors over the two groups (the column total) by the number of subjects in each group (the row total) and dividing the result by the grand total of subjects in the experiment.

> The formula: (column total * row total) / grand total will give you the expected frequencies, however many rows and columns you have.

The total deviance will have a chi-square distribution if the modal is correct. __The degrees of freedom__ are easily calculated using the formula: (number of columns - 1) * 9number of rows - 1)

The Rennellese vowel system has three heights and a front/back distinction.

> Why does the Rennellese version of English plumber, /palama/, select /a/ as the epenthetic vowel to break up the /pl/ cluster?

> The most straightforward explanation would be one of reduplication of the non-epenthetic vowel.

Whenever χ²values based on expected frequencies of less than 5 are reported, the reader's attention should be drawn to this fact and any conclusions arrived at on the basis of statistically significant outcome should be expressed in suitably tentative terms.

> An examination of the use of χ2 in the applied linguistics literature reveals that this is not always done.

When the table has only two rows and two columns the total deviance tends to be rather larger than it ought to be for its distribution to be modelled well as a chi-squared variable with I df. Thus a correction (referred to as 'Yates'correction') is in needed, and takes the following forms.

> As always, for each of the four cells, you must find the difference between expected and observed frequency. Then, ignoring the sign of that difference, reduce its magnitude by 0.5, square the result and divide by the expected value as before.

However, it would be mistaken to use the chi-square test on this data, because the separate utterances which were analysed to obtain the data for the table were not independent of each other.

The data we use to estimate a parameter of a population, or to test a statistical hypothesis, must come from a random sample of the population.

> This is no less true of the chi-squared test for association between the rows and columns of a contingency table.

> In particular, all the instances which have been recorded must be separated and not linked in any way.

Whenever it is not clear that the observations are completely independent, if a chi-squared value is calculated it should be treated very sceptically and attention drawn to possible defects in the sampling method.

There is evidence in applied linguistics publications that the requirement of independence is not generally recognised.

Whenever an individual's contribution to contingency table is more than 'one', then there must be suspicion that the assumption of independence has not been met.

In practice one may very well carry out many tests based on a single data set, but it is important to realise that the results cannot be given as much weight as if each table were based on an independent data sources.
