x̄ has two mathematical properties which sanction its use as an estimator for µ.

1. It is unbiased. The man of an infinitely large number of such sample means would be the man of the population, the very quantity which we wish to estimate.

2. It is a consistent estimator. The larger the sample size, the more closely the values of x̄ will cluster around the population mean, µ.

The mean of any sample can be used to estimate the mean of the population from which the sample is drawn.

A single parameter is usually referred to as a __point estimator__.

Although a point estimator is an indicator of the possible value of the corresponding population parameter, it is of limited usefulness by itself.

The interval x̄±(1.96\*0.5) will contain the value µ about 95% of the time. This interval is called a __95% confidence interval__ for the value of µ.

The sample standard deviation of the sample mean is called the __standard error__ of the sample mean, and the 95% confidence interval is often written as: x̄±1.96.

> The term __standard error__ is generally used to refer to the sample standard deviation of any estimated quantity.

The __t-distribution__ has a symmetric histogram like the normal distribution, but is somewhat flatter. In small samples, however, the t-distribution has a somewhat larger variance than the standard normal distribution.

The size of sample required depends on the distribution of the individual values of the variable being studied and frequently not much will be known about that.

__Central limit theorem__:

> If the variable is not normal but has a population histogram which has a single mode and is roughly symmetrical, i.e. is no more than slightly skewed, then samples of 20 or so will probably be large enough to ensure the normality of the sample mean. Only when the variable in question is highly skewed or has a markedly bi-modal histogram will much larger samples be required. Even then, a sample of, say, 100 observations ought to be large enough.

Information is a commodity which has to be paid for like any other; and resources available to purchase it will always be limited.

A data set consisting of n related values of a variable always contains less information for the estimation of population means and proportions than does a sample of n independent observations of the same variable.

Thus, if it is possible to obtain n independent values at the same cost as n interdependent values it will be more efficient to do so. In particular, if the values are not independent much bigger samples than usual will be needed to assume that the sample means are normally distributed.

If the variable in question has a normal distribution, a confidence interval can be obtained for any sample size using the t-table and the methods of the previous section.

Reduction in the value of data caused by lack of independence also occurs when the data are obtained from several subjects.

√n = 1.96\*5=9.8 n=(9.8)2=96.04, so the sample size is around 100.

In order to be more certain of including the true value we must include more values, thus lengthening the interval.

The lower the confidence level the more chance there is that the stated interval does not include the true value. On the other hand, the higher the confidence level, the wider will be the interval and wide intervals are less informative than narrow ones.

Some compromise must be reached between the level of confidence we might like and the narrow interval we would find useful.
